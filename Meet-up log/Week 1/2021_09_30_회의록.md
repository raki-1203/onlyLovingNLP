## 참석자
김신곤, 김재영, 박세진, 손희락, 심우창, 이상준, 전상민

## 강의 리뷰
[4장](https://drive.google.com/drive/folders/1MLI7SWBS-JM9_2zkSnySplb1YQt8fYaC)  
[5장](https://drive.google.com/drive/folders/1MLI7SWBS-JM9_2zkSnySplb1YQt8fYaC)

## 대회 관련
### 현재
  - **KLUE-RoBERTa-Large**가 현재 최고 성능의 모델
    - epoch 10과 20 차이는 크지 않음... overfitting의 문제가 있는 것 같음

### 각자 역할 분담을 한다면?
  - [hyperparameter_search로 parameter를 tuning](https://stages.ai/competitions/75/discussion/talk/post/651)
    - 각자 hyperparameter를 나누고 최고의 조합을 구하는 방법이 있음
  - model, optimizer 바꾸기
  - data 관련해서 아이디어를 생각해야할 것 같음
    - type을 data에 붙여서 비교하는 등
  - tokenizing부터도 다양하게 시도해볼 수 있음
  - 객체명 인식해서 tag 붙이기
  - class를 30가지로 나누는 대신 layer 또는 model 추가
  - loss 측정 방식 다양화 (근데 이거 좀 어려움)

### 오늘의 결정 사항!
  - 다음 주 일요일(10/3)까지는 자유롭게! 하고 싶은 거 하기!
    - seed는 42. loss도 고정...도 그냥 참고하삼
    - model도 자유임~^.^
  - base code는 본인 거 사용하거나 아님 희락님 거 사용하거나! 이건 자율!
    - 희락님이 batch size 45로 바꿔두셨다고 하니... 참고하삼

## 논문
[RoBERTa](https://arxiv.org/pdf/1907.11692.pdf)
