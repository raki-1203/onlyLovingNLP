## 참석자
김신곤, 김재영, 박세진, 손희락, 심우창, 이상준, 전상민

## 프로젝트 아이디어
이번 주 수요일 멘토링 시간에 공유하기로 했음.  
수요일 피어세션 시간에 최소한 한 개씩은 생각해오기

## 진행 상황
- PR은 실험 성공하면 발표하고 draft 지우기. 이게 최종 merge를 하겠다는 의미.  
- 상준님 : 이슈에 실험 결과 올리기 위해서 열심히 돌렸으나,,, 실수를 하나씩 수정하다보니 아직 게시하지 못했음. 하지만 지금 돌아가고 있는 건 정말...! 정말로...! 진짜로 실수가 없을 거라 오늘 실험 결과 올릴 수 있을 거라고 기대 중~
  - mrc쪽 모델 손보는 실험 해보고 싶음
  - dense embedding 완료 후 merge되면 이거 관련한 것도 같이 해보겠다
- 신곤님 : python script file에서 읽어오는 부분에서 계속 오류가 났음... 이거 때문에 진전이 없었달까,,,~
  - elastic search 파일에서의 접근 권한 문제였음. 아무튼 해결!
  - nori를 안 썼을 때 결과가 나쁘지 않게 나왔음. nori를 사용하지 않는 게 바로 transformer를 사용하지 않는 것. 이거에 대한 결과가 지난 번에 말했던 그 결과.
- 희락님 : 학습 후에 저장된 모델을 가져와서 하도록 했는데 이상한 결과가 나와버렸지뭐야!!!!!!!!
  - 각 context마다의 값이 다 비슷하게 나와버림... wiki에 대한 embedding을 수행한 결과임.
  - sparse가 dense보다 더 빠르고 k가 작을수록 답을 더 잘 찾아버림...
  - 학습했을 때의 결과를 봤을 때 bert-base의 값이 가장 높았음. 근데 roberta small부터의 값이 또 이상해졌어
  - 이것만 잡으면 dense 문제 해결되고 그 뒤에는 재영님의 아이디어를 써보려고 함.
  - 모델 save와 불러오기의 문제라고 생각함
  - 속도 차이는 batch를 나눠서 돌리는 그 부분 때문이 아닐까?
- 재영님 : passage embedding 학습이 다 그냥 똑같이 되어버림. 이거 해결되면 지난 주 DPR 논문의 모든 기능이 구현된 것.
  - 하고 있는 내용에 대해 board에 공유하기...!
- 상민님 : augmentation을 하고 싶었으나 매번 할 때마다 수행하는 것보다는 미리 만들어두는 것이 더 좋다고 생각했음.
  - augmentation된 dataset을 추가하는 것이 아니라 따로 관리를 함으로써 k-fold를 적용할 때마다 다르게 불러와서 하고 싶었음. 이거 하려면 k-fold부터 구현해야할 것 같아서 이 부분 진행 중
  - get_data와 run_mrc의 위치 변경했음. 서로 분리하기 위해서.
  - best prediction만으로는 soft voting이 어려울 것 같아서 n-best prediction을 사용했음.
  - 결과는 기존 roberta-small과 비슷함. 
  - 리더보드에서는 원래 거에 비해 3점정도 올랐음. 근데 원래의 retrieval의 성능이 안 좋기 때문에... 이게 조금 더 개선된다면 점수도 더 오를 수 있지 않을까 기대
  - 오늘은 augmentation 마무리하고 elastic search를 도전해볼까~^^ 생각했음
- 우창님 : 희락님 코드를 바탕으로 encoder custom하는 bi-lstm 만져보려고 했음.
  - 상민님 코드와 klue에서의 bi-lstm 코드 참고했음
  - hidden state vector 두 개를 추가하고 batch * hidden state 연산을 해주기 위해서 convolution vector 압축해줬음.
  - qa에 필요한 마지막 layer 추가하고 30개의 category로 분류
  - 막상 결과는... batch size는 다르지만 custom 했을 때가 6~7% 성능이 더 떨어졌음

## 추가 아이디어
- 현재는 질문의 결과로 cls를 얻고 내적하고 output을 얻는 형태. 근데 내적하지 말고 그냥 전체를 다 사용해보는 것은 어떤가?
  - 내적이 불가하므로 1xN, 1xN으로 만들어서 내적하면... 전체에 대한 정보를 다 쓸 수 있다...!
    - 1 대신에 질문의 길이로 해도 됨.
    - 1로 줄이면 사라지는 정보가 많을 것 같음
    - 차원을 줄이는 과정에서 평균을 내도 되고, 아니면 layer를 써도 되고.
  - hidden size는 줄일 수 있는데 토큰의 길이는 안 줄어들지 않나?
    - convolution이나 평균으로 가능할듯
    - 앞 부분을 transpose해도 되지 않을까
