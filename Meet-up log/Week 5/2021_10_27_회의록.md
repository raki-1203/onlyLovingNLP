## 참석자
김신곤, 김재영, 박세진, 손희락, 심우창, 이상준, 전상민

## 프로젝트 진행 상황
- 상준님 : tf-idf의 tokenizer를 어떤 걸 사용해야할지 모르겠다! 고정을 시키는 게 맞을까? 모델 네임을 어떻게 전달해야할까
  - data_args와 model_name_or_path는 inference 과정에서 바뀐다
  - model이랑 tokenizer name을 다르게 설정해주면? ... 다르게 적어도 덮어씌워지기 때문에 다르게 적용되지 않을 것 같음.
  - 희락님의 pr에서 inference 같이 실행하는 부분...(train.py에서) 인자를 추가했을 때 inference 시에도 그 인자 여부를 좀 적어줬으면 좋겠음
    - retrieval type같은... 그런 것들...
    - 근데 현재 희락님이 이 부분들 수정 중. retrival_type으로 바꾸고 data_args를 model_args로 바꾸고... (sparse, dense, elastic) 세 가지가 있어서 작업 중.
- 재영님 : 학습 안 되는 건 해결했음. 희락님이 dense 구현하신 거 가져와서 잘 하니깐... 되더라...~
  - dpr과 bm25를 비교했을 때 dpr이 더 못 뽑더라,,,~ 되게 뜬금없는 passage를 가져오는 것 같아. 도움이 안 되는 것 같기도 하고... ㅠ.ㅠ
  - k=10, 30으로 re-ranking을 하고 봤는데... 상준님이 올려주신 결과랑 비교했을 때 0.1점정도 높은 수준
  - 학습할 때는 batch size 32로 잡음. 그래서 64개중에 정답 하나 고름. 64개 중에 한 개는 잘 고르는 것 같은데 실제로 retrieval에서 실험을 할 때는 2천 개에서 한 개를 고르기 때문에 거기서는 잘 못 고르는 것 같음
    - batch size 16일 때 너무 별로인 것 같아서 32로 올렸음. 근데 올렸음에도 불구하고 큰 차이는 없었던 것 같음
    - **비교를 위해서는 기준이 정확해야할 것 같아요**
  - bm25는 상준님이랑 똑같음... 근데 dense가 도움이 안 되는 것 같아. normalize를 하고 bm25에 가중치를 1.2배정도 더 주고 나니 dpr이 다 빠져버림.
    - dense에 더 가중치를 주고 실험을 돌리는 것이 좋을듯.
    - dense가 잘 안 됐던 게 학습량의 문제가 아닐까? 생각은 들지만 그래도 혹~시 모르니 가중치 실험도 해보삼
    - k의 크기가 작은 것도 하나의 요인이 되지 않았을까 싶음. 
    - 1등 조는 1:1로 가중치를 뒀을 때 나쁘지 않았다고 써있더라.
  - batch size 8이랑 16이랑 두 개 다 실험 돌려보기!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 으랏촷촤~~~~~~
- 신곤님 : elastic search가 em score랑 과연 관련이 있을까...?라는 생각이 들었음.
- 희락님 : elastic 시도했음. 근데 bm보다 훨씬 빠르더라!!!!!!!!!! 그리고 성능도 좋더라!!!!!!!!!!!
  - elastic이 질문 하나당 search를 한 번씩밖에 못 하더라. 그래서 시간은 비교적 오래 걸림. k가 늘어날수록 더 많은 걸 뽑아오기 때문에도... 행렬 계산의 차이?
  - 결론 : sparse를 쓰려면 elastic이 쓰는 것이 맞다.
  - mecab이랑 elastic search랑 version을 맞춰야 하는 issue가 있음. 그냥 nori를 쓰는 것은 어떤가?
  - nori를 사용해서 비교를 해보고 싶다. 상준님이 k=5, 30을 기준으로 한 번 해주세용.
- 우창님 : Bi-LSTM을 다 해봤는데~ 결과를 보니 좀 많이 처참했음...ㅋㅎㅋ...
  - roberta-small로 학습시키고 wiki에서 찾는 거!로 test해봤을 때... custom한 게 6~7점정도 점수가 떨어지더라.
  - 으흐흑...
  - dense에서 data가 부족할 것 같아서 ai stages에 올라온 데이터 추가! 이거 해보고 싶었음
- 상민님 : 우창님이 직전에 말씀하신 그 글!을 이용해서 augmentation을 수행해보려고 했음. 근데 아직 그 아이디어로 구현한 건 아님ㅋ
  - pororo library 이용해서 translation 하고 aug 하려고 했는데~ 지금까지 봤을 땐 이 pororo의 성능(?)이 굉장히 중요한 부분인듯.

## 논문 review

