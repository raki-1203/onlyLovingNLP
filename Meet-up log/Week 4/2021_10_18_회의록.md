## 참석자   
김신곤, 김재영, 박세진, 손희락, 심우창, 이상준, 전상민  

## 주간 계획
(월), (화): 이번 주 강의 수강

## 회의 내용
- self.compute_metrics = None을 주석처리하면 metrics을 eval step마다 확인할 수 있다. 
- fp16을 True로 적용하면 Train 단계에서 Autocast가 적용되어 학습 시간을 단축시켜준다. 
- model은 roberta-large가 가장 성능이 좋았으나 시간이 오래걸리기 때문에, roberta-small로 실험을 우선 진행할 예정이다 [(참고)](https://github.com/boostcampaitech2/mrc-level2-nlp-04/issues/3)  
- train.py파일의 일부 내용을 따로 모듈 파일로 빼놓자.  
- 변경할 일이 없는 argument들을 미리 정해놓자.
- In progress에서 작업하고 완료되며 Done으로 옮기고, 이슈에 올린 후, 이슈의 링크를 Done에 남겨놓자.



## 아이디어
희락님: 상식 팩트 체크(내기할 때 사실 검증하기 좋음)  
상준님: 메시지 입력했을 때 스팸인지 아닌지 판별  
세진님: 표준어 변환기(Style Transfer모델)  
상민님: 비속어 탐지기(우리가 제한한 단어로만 생성된 시퀀스를 표현)  
